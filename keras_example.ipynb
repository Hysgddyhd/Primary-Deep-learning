{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8665b-cda6-42f6-88a0-5ae5ad125f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module - Chapter 7\n",
    "import numpy \n",
    "import keras\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d8ba3-d636-41ac-84b5-2a941e708e4b",
   "metadata": {},
   "source": [
    "There are two types of modules -\n",
    "\n",
    "keras\n",
    "tensorflow.keras\n",
    "Here we need to use tensorflow.keras\n",
    "\n",
    "You need to import Adam (With Capital A) from tensorflow - Keras ( Not only Keras).\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam # - Works\n",
    "from tensorflow.keras.optimizers import adam # - Does not work\n",
    "from keras.optimizers import Adam            # - Does not work\n",
    "from keras.optimizers import adam            # - Does not work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d7954-1ea1-490c-a9e7-bf7230618c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.loadtxt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056594d-24ee-4ef4-b2a5-8a34108f6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = numpy.loadtxt(r\"C:\\Users\\cloud\\Desktop\\Deep Learning\\data\\pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input and output variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a02de8-a468-4788-830f-8a68c0ba840c",
   "metadata": {},
   "source": [
    "(unicode error) 'unicodeescape':\n",
    "\n",
    "This error occurs, because you are using a normal string as a path. You can use one of the three following solutions to fix your problem:\n",
    "\n",
    "1: Just put r before your normal string. It converts a normal string to a raw string:\n",
    "\n",
    "pandas.read_csv(r\"C:\\Users\\DeePak\\Desktop\\myac.csv\")\n",
    "2:\n",
    "\n",
    "pandas.read_csv(\"C:/Users/DeePak/Desktop/myac.csv\")\n",
    "3:\n",
    "\n",
    "pandas.read_csv(\"C:\\\\Users\\\\DeePak\\\\Desktop\\\\myac.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095de45-846e-4170-9ec0-620d7a5b78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(12, input_dim=8, activation= 'relu' ))\n",
    "model.add(keras.layers.Dense(8, activation= 'relu' ))\n",
    "model.add(keras.layers.Dense(1, activation= 'sigmoid' ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd365e27-303b-44b8-bf7c-c44c3cbd3766",
   "metadata": {},
   "source": [
    "input: 8 -> first hidden layer: 12: -> second hidden layer :8 -> output layer : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042b127-78d2-4b75-a3f7-fbf92a0bf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd9866f-4de8-4dfe-88f2-9d75916fe6d3",
   "metadata": {},
   "source": [
    "https://pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024421c-38c8-4ce9-b39c-fa222a626220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model, feed the data to the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6e444-0998-4261-b4d2-59db584d4d70",
   "metadata": {},
   "source": [
    "epoch is stand for The iterations which training process will run  through the dataset,\n",
    "\n",
    "The batch size defines the number of samples that will be propagated through the network.\n",
    "\n",
    "For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1st to 100th) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101st to 200th) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. Problem might happen with the last set of samples. In our example, we've used 1050 which is not divisible by 100 without remainder. The simplest solution is just to get the final 50 samples and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e045ad5-b6a8-4426-97b5-87b51c6cd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model,challenge it\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db2f54-8948-4422-adec-0fad9e66b9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
