{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf8665b-cda6-42f6-88a0-5ae5ad125f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy \n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9d7954-1ea1-490c-a9e7-bf7230618c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'float'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'#'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0munpack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bytes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Load data from a text file.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "fname : file, str, pathlib.Path, list of str, generator\n",
       "    File, filename, list, or generator to read.  If the filename\n",
       "    extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n",
       "    that generators must return bytes or strings. The strings\n",
       "    in a list or produced by a generator are treated as lines.\n",
       "dtype : data-type, optional\n",
       "    Data-type of the resulting array; default: float.  If this is a\n",
       "    structured data-type, the resulting array will be 1-dimensional, and\n",
       "    each row will be interpreted as an element of the array.  In this\n",
       "    case, the number of columns used must match the number of fields in\n",
       "    the data-type.\n",
       "comments : str or sequence of str or None, optional\n",
       "    The characters or list of characters used to indicate the start of a\n",
       "    comment. None implies no comments. For backwards compatibility, byte\n",
       "    strings will be decoded as 'latin1'. The default is '#'.\n",
       "delimiter : str, optional\n",
       "    The character used to separate the values. For backwards compatibility,\n",
       "    byte strings will be decoded as 'latin1'. The default is whitespace.\n",
       "\n",
       "    .. versionchanged:: 1.23.0\n",
       "       Only single character delimiters are supported. Newline characters\n",
       "       cannot be used as the delimiter.\n",
       "\n",
       "converters : dict or callable, optional\n",
       "    Converter functions to customize value parsing. If `converters` is\n",
       "    callable, the function is applied to all columns, else it must be a\n",
       "    dict that maps column number to a parser function.\n",
       "    See examples for further details.\n",
       "    Default: None.\n",
       "\n",
       "    .. versionchanged:: 1.23.0\n",
       "       The ability to pass a single callable to be applied to all columns\n",
       "       was added.\n",
       "\n",
       "skiprows : int, optional\n",
       "    Skip the first `skiprows` lines, including comments; default: 0.\n",
       "usecols : int or sequence, optional\n",
       "    Which columns to read, with 0 being the first. For example,\n",
       "    ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\n",
       "    The default, None, results in all columns being read.\n",
       "\n",
       "    .. versionchanged:: 1.11.0\n",
       "        When a single column has to be read it is possible to use\n",
       "        an integer instead of a tuple. E.g ``usecols = 3`` reads the\n",
       "        fourth column the same way as ``usecols = (3,)`` would.\n",
       "unpack : bool, optional\n",
       "    If True, the returned array is transposed, so that arguments may be\n",
       "    unpacked using ``x, y, z = loadtxt(...)``.  When used with a\n",
       "    structured data-type, arrays are returned for each field.\n",
       "    Default is False.\n",
       "ndmin : int, optional\n",
       "    The returned array will have at least `ndmin` dimensions.\n",
       "    Otherwise mono-dimensional axes will be squeezed.\n",
       "    Legal values: 0 (default), 1 or 2.\n",
       "\n",
       "    .. versionadded:: 1.6.0\n",
       "encoding : str, optional\n",
       "    Encoding used to decode the inputfile. Does not apply to input streams.\n",
       "    The special value 'bytes' enables backward compatibility workarounds\n",
       "    that ensures you receive byte arrays as results if possible and passes\n",
       "    'latin1' encoded strings to converters. Override this value to receive\n",
       "    unicode arrays and pass strings as input to converters.  If set to None\n",
       "    the system default is used. The default value is 'bytes'.\n",
       "\n",
       "    .. versionadded:: 1.14.0\n",
       "max_rows : int, optional\n",
       "    Read `max_rows` rows of content after `skiprows` lines. The default is\n",
       "    to read all the rows. Note that empty rows containing no data such as\n",
       "    empty lines and comment lines are not counted towards `max_rows`,\n",
       "    while such lines are counted in `skiprows`.\n",
       "\n",
       "    .. versionadded:: 1.16.0\n",
       "\n",
       "    .. versionchanged:: 1.23.0\n",
       "        Lines containing no data, including comment lines (e.g., lines\n",
       "        starting with '#' or as specified via `comments`) are not counted\n",
       "        towards `max_rows`.\n",
       "quotechar : unicode character or None, optional\n",
       "    The character used to denote the start and end of a quoted item.\n",
       "    Occurrences of the delimiter or comment characters are ignored within\n",
       "    a quoted item. The default value is ``quotechar=None``, which means\n",
       "    quoting support is disabled.\n",
       "\n",
       "    If two consecutive instances of `quotechar` are found within a quoted\n",
       "    field, the first is treated as an escape character. See examples.\n",
       "\n",
       "    .. versionadded:: 1.23.0\n",
       "like : array_like, optional\n",
       "    Reference object to allow the creation of arrays which are not\n",
       "    NumPy arrays. If an array-like passed in as ``like`` supports\n",
       "    the ``__array_function__`` protocol, the result will be defined\n",
       "    by it. In this case, it ensures the creation of an array object\n",
       "    compatible with that passed in via this argument.\n",
       "\n",
       "    .. versionadded:: 1.20.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "out : ndarray\n",
       "    Data read from the text file.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "load, fromstring, fromregex\n",
       "genfromtxt : Load data with missing values handled as specified.\n",
       "scipy.io.loadmat : reads MATLAB data files\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This function aims to be a fast reader for simply formatted files.  The\n",
       "`genfromtxt` function provides more sophisticated handling of, e.g.,\n",
       "lines with missing values.\n",
       "\n",
       "Each row in the input text file must have the same number of values to be\n",
       "able to read all values. If all rows do not have same number of values, a\n",
       "subset of up to n columns (where n is the least number of values present\n",
       "in all rows) can be read by specifying the columns via `usecols`.\n",
       "\n",
       ".. versionadded:: 1.10.0\n",
       "\n",
       "The strings produced by the Python float.hex method can be used as\n",
       "input for floats.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from io import StringIO   # StringIO behaves like a file object\n",
       ">>> c = StringIO(\"0 1\\n2 3\")\n",
       ">>> np.loadtxt(c)\n",
       "array([[0., 1.],\n",
       "       [2., 3.]])\n",
       "\n",
       ">>> d = StringIO(\"M 21 72\\nF 35 58\")\n",
       ">>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n",
       "...                      'formats': ('S1', 'i4', 'f4')})\n",
       "array([(b'M', 21, 72.), (b'F', 35, 58.)],\n",
       "      dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])\n",
       "\n",
       ">>> c = StringIO(\"1,0,2\\n3,0,4\")\n",
       ">>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)\n",
       ">>> x\n",
       "array([1., 3.])\n",
       ">>> y\n",
       "array([2., 4.])\n",
       "\n",
       "The `converters` argument is used to specify functions to preprocess the\n",
       "text prior to parsing. `converters` can be a dictionary that maps\n",
       "preprocessing functions to each column:\n",
       "\n",
       ">>> s = StringIO(\"1.618, 2.296\\n3.141, 4.669\\n\")\n",
       ">>> conv = {\n",
       "...     0: lambda x: np.floor(float(x)),  # conversion fn for column 0\n",
       "...     1: lambda x: np.ceil(float(x)),  # conversion fn for column 1\n",
       "... }\n",
       ">>> np.loadtxt(s, delimiter=\",\", converters=conv)\n",
       "array([[1., 3.],\n",
       "       [3., 5.]])\n",
       "\n",
       "`converters` can be a callable instead of a dictionary, in which case it\n",
       "is applied to all columns:\n",
       "\n",
       ">>> s = StringIO(\"0xDE 0xAD\\n0xC0 0xDE\")\n",
       ">>> import functools\n",
       ">>> conv = functools.partial(int, base=16)\n",
       ">>> np.loadtxt(s, converters=conv)\n",
       "array([[222., 173.],\n",
       "       [192., 222.]])\n",
       "\n",
       "This example shows how `converters` can be used to convert a field\n",
       "with a trailing minus sign into a negative number.\n",
       "\n",
       ">>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
       ">>> def conv(fld):\n",
       "...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)\n",
       "...\n",
       ">>> np.loadtxt(s, converters=conv)\n",
       "array([[ 10.01, -31.25],\n",
       "       [ 19.22,  64.31],\n",
       "       [-17.57,  63.94]])\n",
       "\n",
       "Using a callable as the converter can be particularly useful for handling\n",
       "values with different formatting, e.g. floats with underscores:\n",
       "\n",
       ">>> s = StringIO(\"1 2.7 100_000\")\n",
       ">>> np.loadtxt(s, converters=float)\n",
       "array([1.e+00, 2.7e+00, 1.e+05])\n",
       "\n",
       "This idea can be extended to automatically handle values specified in\n",
       "many different formats:\n",
       "\n",
       ">>> def conv(val):\n",
       "...     try:\n",
       "...         return float(val)\n",
       "...     except ValueError:\n",
       "...         return float.fromhex(val)\n",
       ">>> s = StringIO(\"1, 2.5, 3_000, 0b4, 0x1.4000000000000p+2\")\n",
       ">>> np.loadtxt(s, delimiter=\",\", converters=conv, encoding=None)\n",
       "array([1.0e+00, 2.5e+00, 3.0e+03, 1.8e+02, 5.0e+00])\n",
       "\n",
       "Note that with the default ``encoding=\"bytes\"``, the inputs to the\n",
       "converter function are latin-1 encoded byte strings. To deactivate the\n",
       "implicit encoding prior to conversion, use ``encoding=None``\n",
       "\n",
       ">>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n",
       ">>> conv = lambda x: -float(x[:-1]) if x.endswith('-') else float(x)\n",
       ">>> np.loadtxt(s, converters=conv, encoding=None)\n",
       "array([[ 10.01, -31.25],\n",
       "       [ 19.22,  64.31],\n",
       "       [-17.57,  63.94]])\n",
       "\n",
       "Support for quoted fields is enabled with the `quotechar` parameter.\n",
       "Comment and delimiter characters are ignored when they appear within a\n",
       "quoted item delineated by `quotechar`:\n",
       "\n",
       ">>> s = StringIO('\"alpha, #42\", 10.0\\n\"beta, #64\", 2.0\\n')\n",
       ">>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n",
       ">>> np.loadtxt(s, dtype=dtype, delimiter=\",\", quotechar='\"')\n",
       "array([('alpha, #42', 10.), ('beta, #64',  2.)],\n",
       "      dtype=[('label', '<U12'), ('value', '<f8')])\n",
       "\n",
       "Quoted fields can be separated by multiple whitespace characters:\n",
       "\n",
       ">>> s = StringIO('\"alpha, #42\"       10.0\\n\"beta, #64\" 2.0\\n')\n",
       ">>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n",
       ">>> np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='\"')\n",
       "array([('alpha, #42', 10.), ('beta, #64',  2.)],\n",
       "      dtype=[('label', '<U12'), ('value', '<f8')])\n",
       "\n",
       "Two consecutive quote characters within a quoted field are treated as a\n",
       "single escaped character:\n",
       "\n",
       ">>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')\n",
       ">>> np.loadtxt(s, dtype=\"U\", delimiter=\",\", quotechar='\"')\n",
       "array('Hello, my name is \"Monty\"!', dtype='<U26')\n",
       "\n",
       "Read subset of columns when all rows do not contain equal number of values:\n",
       "\n",
       ">>> d = StringIO(\"1 2\\n2 4\\n3 9 12\\n4 16 20\")\n",
       ">>> np.loadtxt(d, usecols=(0, 1))\n",
       "array([[ 1.,  2.],\n",
       "       [ 2.,  4.],\n",
       "       [ 3.,  9.],\n",
       "       [ 4., 16.]])\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\cloud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\numpy\\lib\\npyio.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numpy.loadtxt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8056594d-24ee-4ef4-b2a5-8a34108f6919",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "pima-indians-diabetes.data.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpima-indians-diabetes.data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# split into input and output variables\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m dataset[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m8\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:992\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    990\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 992\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    994\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: pima-indians-diabetes.data.csv not found."
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "# split into input and output variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095de45-846e-4170-9ec0-620d7a5b78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation= relu ))\n",
    "model.add(Dense(8, activation= relu ))\n",
    "model.add(Dense(1, activation= sigmoid ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
